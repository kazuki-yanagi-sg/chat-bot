import ollama          # ollama ã®å…¬å¼ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’åˆ©ç”¨
import requests
import json
import tempfile
import os
import subprocess
from sqlalchemy.future import select
from db import async_session
from models import Speaker

async def prepare_prompt_file(speaker_id: int) -> str:
    async with async_session() as session:
        result = await session.execute(select(Speaker).filter(Speaker.id == speaker_id))
        speaker = result.scalars().first()

    if speaker is None:
        return ""

    prompt_content = speaker.prompt

    if prompt_content:
        prompt_dir = "./prompts"
        os.makedirs(prompt_dir, exist_ok=True)
        filepath = os.path.join(prompt_dir, f"prompt_template{speaker_id}.txt")
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(prompt_content)
        return filepath
    else:
        return ""

# --- Ollama API ã¸å•ã„åˆã‚ã›ã™ã‚‹é–¢æ•° ---
async def query_ollama(input_text, conversation_history, speaker_id=46):
    prompt_path = await prepare_prompt_file(speaker_id)
    if prompt_path and os.path.exists(prompt_path):
        with open(prompt_path, "r", encoding="utf-8") as f:
            prompt_suffix = f.read().strip()
    else:
        prompt_suffix = "300æ–‡å­—ä»¥å†…ã§ç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚"

    modified_prompt = f"{input_text}{prompt_suffix}" + "300æ–‡å­—ä»¥å†…ã§ç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚"
    messages = conversation_history + [{"role": "user", "content": modified_prompt}]

    result = ollama.chat(model="phi4", messages=messages)

    try:
        answer = result['message']['content']
    except (KeyError, IndexError):
        answer = "å›ç­”ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚"

    return answer

# --- VoiceVox ã®éŸ³å£°åˆæˆã‚’è¡Œã†é–¢æ•° ---
def get_voicevox_audio(text, speaker=46):
    print(f"ğŸ” voicevox ã«é€ä¿¡ã™ã‚‹ãƒ‡ãƒ¼ã‚¿: text='{text}', speaker={speaker}")
    
    if not text or not isinstance(speaker, int):
        print("âŒ ç„¡åŠ¹ãªå…¥åŠ›å€¤ã§ã™")
        return None

    params = {"text": text, "speaker": speaker}
    audio_query_url = "http://localhost:50021/audio_query"
    r = requests.post(audio_query_url, params=params)

    if r.status_code != 200:
        print("âŒ audio_query ã«å¤±æ•—ã—ã¾ã—ãŸ:", r.status_code, r.text)
        return None

    query = r.json()

    synthesis_url = "http://localhost:50021/synthesis"
    headers = {"Content-Type": "application/json"}
    r2 = requests.post(synthesis_url, params={"speaker": speaker}, data=json.dumps(query), headers=headers)

    if r2.status_code != 200:
        print("âŒ synthesis ã«å¤±æ•—ã—ã¾ã—ãŸ:", r2.status_code, r2.text)
        return None

    return r2.content

# --- WAV éŸ³å£°ã‚’å†ç”Ÿã™ã‚‹é–¢æ•° ---
# def play_audio(audio_data):
#     """
#     audio_data: WAV ãƒ‡ãƒ¼ã‚¿ã®ãƒã‚¤ãƒŠãƒª
#     """
#     # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãå‡ºã—ã¦å†ç”Ÿï¼ˆsimpleaudio ã‚’åˆ©ç”¨ï¼‰
#     with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as f:
#         f.write(audio_data)
#         filename = f.name
#     try:
#         subprocess.run(["ffplay", "-nodisp", "-autoexit", "-loglevel", "quiet", filename])
#     except Exception as e:
#         print("éŸ³å£°å†ç”Ÿã«å¤±æ•—ã—ã¾ã—ãŸ:", e)
#     finally:
#         os.remove(filename)

conversation_history = []  # éå»ã®ä¼šè©±ã‚’ä¿æŒã™ã‚‹ãƒªã‚¹ãƒˆ

# --- ãƒ¡ã‚¤ãƒ³ã®å¯¾è©±ãƒ«ãƒ¼ãƒ— ---
async def comment(user_input: str, speaker: int):
    global conversation_history
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ä¼šè©±å±¥æ­´ã«è¿½åŠ 
    conversation_history.append({"role": "user", "content": user_input})
    
    # ollama ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ç”¨ã„ã¦å•ã„åˆã‚ã›ï¼ˆãƒ¢ãƒ‡ãƒ«: phi4ï¼‰
    answer = await query_ollama(user_input, conversation_history, speaker)
    print("AI ã®å›ç­”: ", answer)
    conversation_history.append({"role": "assistant", "content": answer})
    
    # VoiceVox ã«ã‚ˆã‚ŠéŸ³å£°åˆæˆã—å†ç”Ÿ
    audio = get_voicevox_audio(answer, speaker)
    # if audio:
    #     play_audio(audio)
    return {"answer": answer, "audio": audio}
